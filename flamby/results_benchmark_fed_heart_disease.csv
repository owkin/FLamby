Test,Method,Metric,learning_rate,mu,tau,server_learning_rate,beta1,beta2,optimizer_class
client_test_0,Pooled Training,0.8173076923076923,0.001,,,,,,<class 'torch.optim.adam.Adam'>
client_test_1,Pooled Training,0.8202247191011236,0.001,,,,,,<class 'torch.optim.adam.Adam'>
client_test_2,Pooled Training,0.8125,0.001,,,,,,<class 'torch.optim.adam.Adam'>
client_test_3,Pooled Training,0.8444444444444444,0.001,,,,,,<class 'torch.optim.adam.Adam'>
Pooled Test,Pooled Training,0.8228346456692913,0.001,,,,,,<class 'torch.optim.adam.Adam'>
client_test_0,Local 0,0.7403846153846154,0.001,,,,,,<class 'torch.optim.adam.Adam'>
client_test_1,Local 0,0.7865168539325843,0.001,,,,,,<class 'torch.optim.adam.Adam'>
client_test_2,Local 0,0.5625,0.001,,,,,,<class 'torch.optim.adam.Adam'>
client_test_3,Local 0,0.7777777777777778,0.001,,,,,,<class 'torch.optim.adam.Adam'>
Pooled Test,Local 0,0.7519685039370079,0.001,,,,,,<class 'torch.optim.adam.Adam'>
client_test_0,Local 1,0.7307692307692307,0.001,,,,,,<class 'torch.optim.adam.Adam'>
client_test_1,Local 1,0.7752808988764045,0.001,,,,,,<class 'torch.optim.adam.Adam'>
client_test_2,Local 1,0.125,0.001,,,,,,<class 'torch.optim.adam.Adam'>
client_test_3,Local 1,0.6888888888888889,0.001,,,,,,<class 'torch.optim.adam.Adam'>
Pooled Test,Local 1,0.7007874015748031,0.001,,,,,,<class 'torch.optim.adam.Adam'>
client_test_0,Local 2,0.5384615384615384,0.001,,,,,,<class 'torch.optim.adam.Adam'>
client_test_1,Local 2,0.6292134831460674,0.001,,,,,,<class 'torch.optim.adam.Adam'>
client_test_2,Local 2,0.9375,0.001,,,,,,<class 'torch.optim.adam.Adam'>
client_test_3,Local 2,0.4222222222222222,0.001,,,,,,<class 'torch.optim.adam.Adam'>
Pooled Test,Local 2,0.5748031496062992,0.001,,,,,,<class 'torch.optim.adam.Adam'>
client_test_0,Local 3,0.4519230769230769,0.001,,,,,,<class 'torch.optim.adam.Adam'>
client_test_1,Local 3,0.3258426966292135,0.001,,,,,,<class 'torch.optim.adam.Adam'>
client_test_2,Local 3,0.5625,0.001,,,,,,<class 'torch.optim.adam.Adam'>
client_test_3,Local 3,0.6444444444444445,0.001,,,,,,<class 'torch.optim.adam.Adam'>
Pooled Test,Local 3,0.44881889763779526,0.001,,,,,,<class 'torch.optim.adam.Adam'>
client_test_0,Ensemble,0.7307692307692307,0.001,,,,,,<class 'torch.optim.adam.Adam'>
client_test_1,Ensemble,0.7303370786516854,0.001,,,,,,<class 'torch.optim.adam.Adam'>
client_test_2,Ensemble,0.75,0.001,,,,,,<class 'torch.optim.adam.Adam'>
client_test_3,Ensemble,0.7555555555555555,0.001,,,,,,<class 'torch.optim.adam.Adam'>
Pooled Test,Ensemble,0.7362204724409449,0.001,,,,,,<class 'torch.optim.adam.Adam'>
client_test_0,FedAvg1,0.7884615384615384,0.001,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_1,FedAvg1,0.7865168539325843,0.001,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_2,FedAvg1,0.6875,0.001,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_3,FedAvg1,0.7333333333333333,0.001,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
Pooled Test,FedAvg1,0.7716535433070866,0.001,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_0,FedProx1,0.7596153846153846,0.001,0.1,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_1,FedProx1,0.8089887640449438,0.001,0.1,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_2,FedProx1,0.8125,0.001,0.1,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_3,FedProx1,0.8,0.001,0.1,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
Pooled Test,FedProx1,0.7874015748031497,0.001,0.1,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_0,FedAdagrad1,0.7788461538461539,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_1,FedAdagrad1,0.7752808988764045,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_2,FedAdagrad1,0.8125,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_3,FedAdagrad1,0.8444444444444444,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
Pooled Test,FedAdagrad1,0.7913385826771654,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_0,FedAdam1,0.46153846153846156,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_1,FedAdam1,0.3707865168539326,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_2,FedAdam1,0.9375,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_3,FedAdam1,0.7777777777777778,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
Pooled Test,FedAdam1,0.515748031496063,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_0,FedYogi1,0.5384615384615384,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_1,FedYogi1,0.6292134831460674,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_2,FedYogi1,0.9375,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_3,FedYogi1,0.4222222222222222,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
Pooled Test,FedYogi1,0.5748031496062992,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_0,Cyclic1,0.5384615384615384,1e-05,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_1,Cyclic1,0.6292134831460674,1e-05,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_2,Cyclic1,0.0625,1e-05,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_3,Cyclic1,0.2222222222222222,1e-05,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
Pooled Test,Cyclic1,0.484251968503937,1e-05,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_0,Scaffold1,0.46153846153846156,0.001,nan,nan,1.0,nan,nan,<class 'torch.optim.sgd.SGD'>
client_test_1,Scaffold1,0.3707865168539326,0.001,nan,nan,1.0,nan,nan,<class 'torch.optim.sgd.SGD'>
client_test_2,Scaffold1,0.9375,0.001,nan,nan,1.0,nan,nan,<class 'torch.optim.sgd.SGD'>
client_test_3,Scaffold1,0.7777777777777778,0.001,nan,nan,1.0,nan,nan,<class 'torch.optim.sgd.SGD'>
Pooled Test,Scaffold1,0.515748031496063,0.001,nan,nan,1.0,nan,nan,<class 'torch.optim.sgd.SGD'>
client_test_0,FedAvg10,0.75,0.001,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_1,FedAvg10,0.8089887640449438,0.001,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_2,FedAvg10,0.8125,0.001,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_3,FedAvg10,0.8222222222222222,0.001,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
Pooled Test,FedAvg10,0.7874015748031497,0.001,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_0,FedProx10,0.8173076923076923,0.001,0.1,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_1,FedProx10,0.7865168539325843,0.001,0.1,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_2,FedProx10,0.6875,0.001,0.1,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_3,FedProx10,0.8,0.001,0.1,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
Pooled Test,FedProx10,0.7952755905511811,0.001,0.1,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_0,FedAdagrad10,0.7788461538461539,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_1,FedAdagrad10,0.8202247191011236,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_2,FedAdagrad10,0.75,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_3,FedAdagrad10,0.7777777777777778,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
Pooled Test,FedAdagrad10,0.7913385826771654,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_0,FedAdam10,0.46153846153846156,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_1,FedAdam10,0.3707865168539326,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_2,FedAdam10,0.9375,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_3,FedAdam10,0.7777777777777778,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
Pooled Test,FedAdam10,0.515748031496063,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_0,FedYogi10,0.46153846153846156,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_1,FedYogi10,0.3707865168539326,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_2,FedYogi10,0.9375,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_3,FedYogi10,0.7777777777777778,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
Pooled Test,FedYogi10,0.515748031496063,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_0,Cyclic10,0.5384615384615384,1e-05,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_1,Cyclic10,0.6292134831460674,1e-05,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_2,Cyclic10,0.0625,1e-05,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_3,Cyclic10,0.2222222222222222,1e-05,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
Pooled Test,Cyclic10,0.484251968503937,1e-05,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_0,Scaffold10,0.46153846153846156,0.001,nan,nan,1.0,nan,nan,<class 'torch.optim.sgd.SGD'>
client_test_1,Scaffold10,0.3707865168539326,0.001,nan,nan,1.0,nan,nan,<class 'torch.optim.sgd.SGD'>
client_test_2,Scaffold10,0.9375,0.001,nan,nan,1.0,nan,nan,<class 'torch.optim.sgd.SGD'>
client_test_3,Scaffold10,0.7777777777777778,0.001,nan,nan,1.0,nan,nan,<class 'torch.optim.sgd.SGD'>
Pooled Test,Scaffold10,0.515748031496063,0.001,nan,nan,1.0,nan,nan,<class 'torch.optim.sgd.SGD'>
client_test_0,FedAvg100,0.75,0.001,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_1,FedAvg100,0.8089887640449438,0.001,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_2,FedAvg100,0.6875,0.001,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_3,FedAvg100,0.7777777777777778,0.001,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
Pooled Test,FedAvg100,0.7716535433070866,0.001,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_0,FedProx100,0.7403846153846154,0.001,0.1,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_1,FedProx100,0.7865168539325843,0.001,0.1,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_2,FedProx100,0.6875,0.001,0.1,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_3,FedProx100,0.7777777777777778,0.001,0.1,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
Pooled Test,FedProx100,0.7598425196850394,0.001,0.1,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_0,FedAdagrad100,0.7019230769230769,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_1,FedAdagrad100,0.8426966292134831,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_2,FedAdagrad100,0.0625,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_3,FedAdagrad100,0.6444444444444445,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
Pooled Test,FedAdagrad100,0.7007874015748031,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_0,FedAdam100,0.46153846153846156,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_1,FedAdam100,0.3707865168539326,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_2,FedAdam100,0.9375,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_3,FedAdam100,0.7777777777777778,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
Pooled Test,FedAdam100,0.515748031496063,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_0,FedYogi100,0.46153846153846156,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_1,FedYogi100,0.3707865168539326,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_2,FedYogi100,0.9375,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_3,FedYogi100,0.7777777777777778,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
Pooled Test,FedYogi100,0.515748031496063,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_0,Cyclic100,0.5384615384615384,1e-05,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_1,Cyclic100,0.6292134831460674,1e-05,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_2,Cyclic100,0.0625,1e-05,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_3,Cyclic100,0.2222222222222222,1e-05,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
Pooled Test,Cyclic100,0.484251968503937,1e-05,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_0,Scaffold100,0.46153846153846156,0.001,nan,nan,1.0,nan,nan,<class 'torch.optim.sgd.SGD'>
client_test_1,Scaffold100,0.3707865168539326,0.001,nan,nan,1.0,nan,nan,<class 'torch.optim.sgd.SGD'>
client_test_2,Scaffold100,0.9375,0.001,nan,nan,1.0,nan,nan,<class 'torch.optim.sgd.SGD'>
client_test_3,Scaffold100,0.7777777777777778,0.001,nan,nan,1.0,nan,nan,<class 'torch.optim.sgd.SGD'>
Pooled Test,Scaffold100,0.515748031496063,0.001,nan,nan,1.0,nan,nan,<class 'torch.optim.sgd.SGD'>
client_test_0,FedAvg500,0.8173076923076923,0.001,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_1,FedAvg500,0.8089887640449438,0.001,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_2,FedAvg500,0.5625,0.001,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_3,FedAvg500,0.7777777777777778,0.001,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
Pooled Test,FedAvg500,0.7913385826771654,0.001,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_0,FedProx500,0.7211538461538461,0.001,0.1,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_1,FedProx500,0.7415730337078652,0.001,0.1,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_2,FedProx500,0.625,0.001,0.1,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_3,FedProx500,0.7777777777777778,0.001,0.1,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
Pooled Test,FedProx500,0.7322834645669292,0.001,0.1,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_0,FedAdagrad500,0.5384615384615384,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_1,FedAdagrad500,0.6292134831460674,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_2,FedAdagrad500,0.0625,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_3,FedAdagrad500,0.2222222222222222,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
Pooled Test,FedAdagrad500,0.484251968503937,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_0,FedAdam500,0.5384615384615384,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_1,FedAdam500,0.6292134831460674,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_2,FedAdam500,0.0625,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_3,FedAdam500,0.2222222222222222,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
Pooled Test,FedAdam500,0.484251968503937,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_0,FedYogi500,0.5384615384615384,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_1,FedYogi500,0.6292134831460674,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_2,FedYogi500,0.0625,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_3,FedYogi500,0.2222222222222222,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
Pooled Test,FedYogi500,0.484251968503937,0.0001,nan,1e-08,0.1,0.9,0.999,<class 'torch.optim.sgd.SGD'>
client_test_0,Cyclic500,0.5384615384615384,1e-05,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_1,Cyclic500,0.6292134831460674,1e-05,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_2,Cyclic500,0.0625,1e-05,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_3,Cyclic500,0.2222222222222222,1e-05,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
Pooled Test,Cyclic500,0.484251968503937,1e-05,nan,nan,nan,nan,nan,<class 'torch.optim.adam.Adam'>
client_test_0,Scaffold500,0.47115384615384615,0.001,nan,nan,1.0,nan,nan,<class 'torch.optim.sgd.SGD'>
client_test_1,Scaffold500,0.38202247191011235,0.001,nan,nan,1.0,nan,nan,<class 'torch.optim.sgd.SGD'>
client_test_2,Scaffold500,0.0625,0.001,nan,nan,1.0,nan,nan,<class 'torch.optim.sgd.SGD'>
client_test_3,Scaffold500,0.5777777777777777,0.001,nan,nan,1.0,nan,nan,<class 'torch.optim.sgd.SGD'>
Pooled Test,Scaffold500,0.4330708661417323,0.001,nan,nan,1.0,nan,nan,<class 'torch.optim.sgd.SGD'>
